{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's interesting to note that in deep learning, the evolution of architecture and techniques is very rapid, but certain aspects can remain in bits of code for years without really knowing if they're really necessary. Most of the time, we take it for granted that they have been optimized and should not be bothered with.\n",
    "\n",
    "One such aspect is the *input normalization* applied to the input of most convolutional neural networks (CNNs) used to process visual images. This is especially true since we often use networks in the community that are pre-trained on images normalized to given values, such as VGG or ResNET. If you ask Github's Copilot, it says that:\n",
    "\n",
    ">    Image normalization in convolutional neural networks (CNNs) has several beneficial effects:\n",
    ">    1- Improved convergence: Normalization helps to stabilize and speed up the learning process by ensuring that pixel values are in a similar range, thus facilitating optimization.\n",
    ">    2- Reduced sensitivity to scale variations: Normalizing images reduces the model's sensitivity to scale variations in pixel values, which can improve model robustness.\n",
    ">    3- Prevention of neuron saturation: Unnormalized pixel values can lead to neuron saturation, which slows down learning. Normalization helps prevent this problem.\n",
    ">    4- Improved performance: In general, image normalization can lead to better model performance in terms of accuracy and generalization.\n",
    "\n",
    "**I'm interested here in whether these networks remain effective when we change the input normalization.** In fact, since the weights of the first convolutional layer are learned, and since convolution kernels can be multiplied by arbitrary values thanks to the bias in the convolutions, it makes no sense to normalize to a certain value, but simply to normalize. This is even more obvious when these values are given with 3-digit precision! I propose here to show quantitatively that this is the case, first for a *historical* network [LeNet](https://en.wikipedia.org/wiki/LeNet) applied to the MNIST challenge, and then for [ResNet](https://en.wikipedia.org/wiki/Residual_neural_network) applied to ImageNet.\n",
    "\n",
    "\n",
    "<!-- TEASER_END -->\n",
    "\n",
    "Let's first initialize the notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T15:41:03.841801Z",
     "iopub.status.busy": "2024-12-22T15:41:03.841652Z",
     "iopub.status.idle": "2024-12-22T15:41:04.051837Z",
     "shell.execute_reply": "2024-12-22T15:41:04.051320Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(precision=6, suppress=True)\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "phi = (np.sqrt(5)+1)/2\n",
    "fig_width = 10\n",
    "figsize = (fig_width, fig_width/phi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T15:41:04.053348Z",
     "iopub.status.busy": "2024-12-22T15:41:04.053191Z",
     "iopub.status.idle": "2024-12-22T15:41:05.763039Z",
     "shell.execute_reply": "2024-12-22T15:41:05.762521Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -Uq -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T15:41:05.779553Z",
     "iopub.status.busy": "2024-12-22T15:41:05.779451Z",
     "iopub.status.idle": "2024-12-22T15:41:05.889200Z",
     "shell.execute_reply": "2024-12-22T15:41:05.888648Z"
    }
   },
   "outputs": [],
   "source": [
    "%mkdir -p data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The MNIST challenge and the *French Touche* \n",
    "\n",
    "First, let's explore the *LeNet* network  (Lecun, Y.; Bottou, L.; Bengio, Y.; Haffner, P. (1998). \"Gradient-based learning applied to document recognition\" (PDF). Proceedings of the IEEE. 86 (11): 2278–2324. doi:10.1109/5.726791. S2CID 14542261), whose objective is to categorize images of written digits, one of the first great successes of Multilayer neural networks. For this one, we're going to use the classic implementation, as proposed in the PyTorch library example series. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The cell below allows you to do everything: first load the libraries, then define the neural network, and finally define the learning and testing procedures that are applied to the database. The output accuracy value corresponds to the percentage of letters that are correctly classified.\n",
    "\n",
    "In this cell, we'll isolate the two parameters used to set the mean and standard deviation applied to the normalization function, which we'll be manipulating in the course of this book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T15:41:05.890909Z",
     "iopub.status.busy": "2024-12-22T15:41:05.890793Z",
     "iopub.status.idle": "2024-12-22T15:41:06.969543Z",
     "shell.execute_reply": "2024-12-22T15:41:06.969296Z"
    }
   },
   "outputs": [],
   "source": [
    "# adapted from https://raw.githubusercontent.com/pytorch/examples/refs/heads/main/mnist/main.py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau\n",
    "\n",
    "epochs = 15\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output\n",
    "\n",
    "\n",
    "def train(model, device, train_loader, optimizer, epoch, log_interval=100, verbose=True):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if verbose and batch_idx % log_interval  == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "\n",
    "def test(model, device, test_loader, verbose=True):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    if verbose:\n",
    "        print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    return correct / len(test_loader.dataset)\n",
    "\n",
    "\n",
    "def main(mean, std, weight_init=None, bias_init=None, epochs=epochs, log_interval=100, verbose=False):\n",
    "    # Training settings\n",
    "    torch.manual_seed(1998) # FOOTIX rules !\n",
    "    train_kwargs = {'batch_size': 64}\n",
    "    test_kwargs = {'batch_size': 1000}\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "        cuda_kwargs = {'num_workers': 1,\n",
    "                       'pin_memory': True,\n",
    "                       'shuffle': True}\n",
    "        train_kwargs.update(cuda_kwargs)\n",
    "        test_kwargs.update(cuda_kwargs)\n",
    "    elif torch.backends.mps.is_available():\n",
    "        device = torch.device(\"mps\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "\n",
    "    if mean is None:\n",
    "        transform = transforms.ToTensor()\n",
    "    else:\n",
    "        transform=transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((mean,), (std,))\n",
    "            ])\n",
    "    dataset1 = datasets.MNIST('data', train=True, download=True,\n",
    "                       transform=transform)\n",
    "    train_loader = torch.utils.data.DataLoader(dataset1, **train_kwargs)\n",
    "\n",
    "    dataset2 = datasets.MNIST('data', train=False,\n",
    "                       transform=transform)\n",
    "    test_loader = torch.utils.data.DataLoader(dataset2, **test_kwargs)\n",
    "\n",
    "    model = Net().to(device)\n",
    "\n",
    "    if not bias_init is None:\n",
    "        model.conv1.bias.data *= bias_init\n",
    "    if not weight_init is None:\n",
    "        model.conv1.weight.data *= weight_init\n",
    "\n",
    "    \n",
    "    optimizer = optim.Adadelta(model.parameters(), lr=1.0)\n",
    "    # scheduler = StepLR(optimizer, step_size=1, gamma=0.7)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, 'max')\n",
    "    for epoch in range(1, epochs+1):\n",
    "        train(model, device, train_loader, optimizer, epoch, log_interval=log_interval, verbose=verbose)\n",
    "        accuracy = test(model, device, test_loader, verbose=verbose)\n",
    "        scheduler.step(accuracy)\n",
    "\n",
    "    if verbose: print(f'The std of weight and bias in the first convolutional layer is {model.conv1.weight.std().item():.4f} and  {model.conv1.bias.std().item():.4f}')\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(You will notice that I made minor changes, such as using the `ReduceLROnPlateau` scheduler instead of `StepLR`. In practice, this only changed the values I could test - run the notebook with enough epochs and the other scheduler to see for yourself.)\n",
    "\n",
    "Now that we've defined the entire protocol, we can test it in its most classic form, as delivered in the original code, with 3-digit precision (!):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T15:41:06.971131Z",
     "iopub.status.busy": "2024-12-22T15:41:06.970998Z",
     "iopub.status.idle": "2024-12-22T15:41:54.172995Z",
     "shell.execute_reply": "2024-12-22T15:41:54.172604Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.304859\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.289305\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.213311\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.308440\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.147784\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.176286\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.155225\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.146125\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.139085\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.113915\n",
      "\n",
      "Test set: Average loss: 0.0500, Accuracy: 9830/10000 (98%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.066308\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.158526\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.119711\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.136787\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.025995\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.091009\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.082308\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.030041\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.181695\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.039962\n",
      "\n",
      "Test set: Average loss: 0.0362, Accuracy: 9874/10000 (99%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.015047\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.142060\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.043031\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.105732\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.007703\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.040002\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.072677\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.081067\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.218688\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.052170\n",
      "\n",
      "Test set: Average loss: 0.0345, Accuracy: 9868/10000 (99%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.014175\n",
      "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.176472\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.076187\n",
      "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.133114\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.059949\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.040658\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.037781\n",
      "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.019609\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.172807\n",
      "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.022148\n",
      "\n",
      "Test set: Average loss: 0.0325, Accuracy: 9895/10000 (99%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.021612\n",
      "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.097492\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.055108\n",
      "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.072939\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.062699\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.005354\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.006854\n",
      "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.033424\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.191006\n",
      "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.061297\n",
      "\n",
      "Test set: Average loss: 0.0351, Accuracy: 9880/10000 (99%)\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.026589\n",
      "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.008733\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.007126\n",
      "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.031139\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.025567\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.070778\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.049918\n",
      "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.038061\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.130356\n",
      "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.005676\n",
      "\n",
      "Test set: Average loss: 0.0382, Accuracy: 9882/10000 (99%)\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.009336\n",
      "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.051505\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.004363\n",
      "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.046023\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.026038\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.024678\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.017313\n",
      "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.093079\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.139670\n",
      "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.020203\n",
      "\n",
      "Test set: Average loss: 0.0310, Accuracy: 9908/10000 (99%)\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.002461\n",
      "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.007145\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.048787\n",
      "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.204105\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.093761\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.045757\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.026321\n",
      "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.008209\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.132413\n",
      "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.029897\n",
      "\n",
      "Test set: Average loss: 0.0356, Accuracy: 9896/10000 (99%)\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.010256\n",
      "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.096294\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.117168\n",
      "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.046827\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.005230\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.015085\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.000422\n",
      "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.005348\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.207676\n",
      "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.004505\n",
      "\n",
      "Test set: Average loss: 0.0333, Accuracy: 9895/10000 (99%)\n",
      "\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.003484\n",
      "Train Epoch: 10 [6400/60000 (11%)]\tLoss: 0.048959\n",
      "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.000684\n",
      "Train Epoch: 10 [19200/60000 (32%)]\tLoss: 0.056301\n",
      "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.001280\n",
      "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 0.002467\n",
      "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.065457\n",
      "Train Epoch: 10 [44800/60000 (75%)]\tLoss: 0.012744\n",
      "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.332403\n",
      "Train Epoch: 10 [57600/60000 (96%)]\tLoss: 0.000213\n",
      "\n",
      "Test set: Average loss: 0.0348, Accuracy: 9907/10000 (99%)\n",
      "\n",
      "Train Epoch: 11 [0/60000 (0%)]\tLoss: 0.002512\n",
      "Train Epoch: 11 [6400/60000 (11%)]\tLoss: 0.077619\n",
      "Train Epoch: 11 [12800/60000 (21%)]\tLoss: 0.003367\n",
      "Train Epoch: 11 [19200/60000 (32%)]\tLoss: 0.040367\n",
      "Train Epoch: 11 [25600/60000 (43%)]\tLoss: 0.040819\n",
      "Train Epoch: 11 [32000/60000 (53%)]\tLoss: 0.001722\n",
      "Train Epoch: 11 [38400/60000 (64%)]\tLoss: 0.079866\n",
      "Train Epoch: 11 [44800/60000 (75%)]\tLoss: 0.000790\n",
      "Train Epoch: 11 [51200/60000 (85%)]\tLoss: 0.116758\n",
      "Train Epoch: 11 [57600/60000 (96%)]\tLoss: 0.004672\n",
      "\n",
      "Test set: Average loss: 0.0329, Accuracy: 9896/10000 (99%)\n",
      "\n",
      "Train Epoch: 12 [0/60000 (0%)]\tLoss: 0.037936\n",
      "Train Epoch: 12 [6400/60000 (11%)]\tLoss: 0.012845\n",
      "Train Epoch: 12 [12800/60000 (21%)]\tLoss: 0.001950\n",
      "Train Epoch: 12 [19200/60000 (32%)]\tLoss: 0.081822\n",
      "Train Epoch: 12 [25600/60000 (43%)]\tLoss: 0.024159\n",
      "Train Epoch: 12 [32000/60000 (53%)]\tLoss: 0.002309\n",
      "Train Epoch: 12 [38400/60000 (64%)]\tLoss: 0.003081\n",
      "Train Epoch: 12 [44800/60000 (75%)]\tLoss: 0.015278\n",
      "Train Epoch: 12 [51200/60000 (85%)]\tLoss: 0.085052\n",
      "Train Epoch: 12 [57600/60000 (96%)]\tLoss: 0.028177\n",
      "\n",
      "Test set: Average loss: 0.0278, Accuracy: 9920/10000 (99%)\n",
      "\n",
      "Train Epoch: 13 [0/60000 (0%)]\tLoss: 0.011958\n",
      "Train Epoch: 13 [6400/60000 (11%)]\tLoss: 0.008858\n",
      "Train Epoch: 13 [12800/60000 (21%)]\tLoss: 0.003677\n",
      "Train Epoch: 13 [19200/60000 (32%)]\tLoss: 0.003108\n",
      "Train Epoch: 13 [25600/60000 (43%)]\tLoss: 0.000039\n",
      "Train Epoch: 13 [32000/60000 (53%)]\tLoss: 0.031428\n",
      "Train Epoch: 13 [38400/60000 (64%)]\tLoss: 0.045575\n",
      "Train Epoch: 13 [44800/60000 (75%)]\tLoss: 0.002322\n",
      "Train Epoch: 13 [51200/60000 (85%)]\tLoss: 0.132071\n",
      "Train Epoch: 13 [57600/60000 (96%)]\tLoss: 0.021138\n",
      "\n",
      "Test set: Average loss: 0.0327, Accuracy: 9907/10000 (99%)\n",
      "\n",
      "Train Epoch: 14 [0/60000 (0%)]\tLoss: 0.009047\n",
      "Train Epoch: 14 [6400/60000 (11%)]\tLoss: 0.001646\n",
      "Train Epoch: 14 [12800/60000 (21%)]\tLoss: 0.024658\n",
      "Train Epoch: 14 [19200/60000 (32%)]\tLoss: 0.036796\n",
      "Train Epoch: 14 [25600/60000 (43%)]\tLoss: 0.003261\n",
      "Train Epoch: 14 [32000/60000 (53%)]\tLoss: 0.037732\n",
      "Train Epoch: 14 [38400/60000 (64%)]\tLoss: 0.002635\n",
      "Train Epoch: 14 [44800/60000 (75%)]\tLoss: 0.073126\n",
      "Train Epoch: 14 [51200/60000 (85%)]\tLoss: 0.338539\n",
      "Train Epoch: 14 [57600/60000 (96%)]\tLoss: 0.014808\n",
      "\n",
      "Test set: Average loss: 0.0301, Accuracy: 9914/10000 (99%)\n",
      "\n",
      "Train Epoch: 15 [0/60000 (0%)]\tLoss: 0.015033\n",
      "Train Epoch: 15 [6400/60000 (11%)]\tLoss: 0.025276\n",
      "Train Epoch: 15 [12800/60000 (21%)]\tLoss: 0.046819\n",
      "Train Epoch: 15 [19200/60000 (32%)]\tLoss: 0.026202\n",
      "Train Epoch: 15 [25600/60000 (43%)]\tLoss: 0.095449\n",
      "Train Epoch: 15 [32000/60000 (53%)]\tLoss: 0.001747\n",
      "Train Epoch: 15 [38400/60000 (64%)]\tLoss: 0.000561\n",
      "Train Epoch: 15 [44800/60000 (75%)]\tLoss: 0.000422\n",
      "Train Epoch: 15 [51200/60000 (85%)]\tLoss: 0.135098\n",
      "Train Epoch: 15 [57600/60000 (96%)]\tLoss: 0.023550\n",
      "\n",
      "Test set: Average loss: 0.0315, Accuracy: 9906/10000 (99%)\n",
      "\n",
      "The std of weight and bias in the first convolutional layer is 0.2196 and  0.1221\n",
      "accuracy=0.9906\n"
     ]
    }
   ],
   "source": [
    "accuracy = main(mean=0.1307, std=0.3081, verbose=True)\n",
    "print(f'{accuracy=:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For image normalization in LeNet  the standard values used are for ImageNet training:\n",
    "\n",
    "* `mean=0.1307`, \n",
    "* `std=0.3081`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These exact same numbers were first introduced in that code on [Jan 17, 2017](https://github.com/pytorch/examples/commit/32c7386aef93737926069ee284d827f8e954e086) and these exact values have not changed since (up to the 3rd digit).\n",
    "\n",
    "What is less known is that they may be retrieved from te datasets' statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:58: SyntaxWarning: invalid escape sequence '\\M'\n",
      "<>:66: SyntaxWarning: invalid escape sequence '\\M'\n",
      "<>:58: SyntaxWarning: invalid escape sequence '\\M'\n",
      "<>:66: SyntaxWarning: invalid escape sequence '\\M'\n",
      "/var/folders/3s/q2x8bxzj43g4rdvb2wjt67640000gq/T/ipykernel_61960/2211814349.py:58: SyntaxWarning: invalid escape sequence '\\M'\n",
      "  print(\"\\MNIST stats on the train set:\")\n",
      "/var/folders/3s/q2x8bxzj43g4rdvb2wjt67640000gq/T/ipykernel_61960/2211814349.py:66: SyntaxWarning: invalid escape sequence '\\M'\n",
      "  print(\"\\MNIST stats on the test set:\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing mean...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:03<00:00, 76.03it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing standard deviation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:02<00:00, 80.76it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\MNIST stats on the train set:\n",
      "Mean: 0.1307\n",
      "Std: 0.3081\n",
      "Computing mean...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:02<00:00, 16.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing standard deviation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:02<00:00, 17.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\MNIST stats on the test set:\n",
      "Mean: 0.1325\n",
      "Std: 0.3105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "def compute_dataset_stats(dataset, batch_size=256, num_workers=4):\n",
    "    \"\"\"\n",
    "    Calculate the channel-wise mean and standard deviation of a data set\n",
    "    \n",
    "    Args:\n",
    "        dataset: the dataset to compute the statistics from\n",
    "        batch_size: Batch size for loading data\n",
    "        num_workers: Number of worker processes to load data\n",
    "    \n",
    "    Returns:\n",
    "        Means: Means per channel\n",
    "        stds: Channel-wise standard deviations\n",
    "    \"\"\"\n",
    "\n",
    "    loader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    # Initialize variables for computing means\n",
    "    mean = torch.zeros(3)\n",
    "    mean_squared = torch.zeros(3)\n",
    "    total_images = 0\n",
    "    \n",
    "    print(\"Computing mean...\")\n",
    "    # First pass: compute mean\n",
    "    for images, _ in tqdm(loader):\n",
    "        batch_samples = images.size(0)\n",
    "        images = images.view(batch_samples, images.size(1), -1)\n",
    "        mean += images.mean(2).sum(0)\n",
    "        total_images += batch_samples\n",
    "    \n",
    "    mean = mean / total_images\n",
    "    \n",
    "    print(\"Computing standard deviation...\")\n",
    "    # Second pass: compute std\n",
    "    for images, _ in tqdm(loader):\n",
    "        batch_samples = images.size(0)\n",
    "        images = images.view(batch_samples, images.size(1), -1)\n",
    "        mean_squared += ((images - mean.view(3, 1))**2).mean(2).sum(0)\n",
    "    \n",
    "    std = torch.sqrt(mean_squared / total_images)\n",
    "    \n",
    "    return mean.tolist(), std.tolist()\n",
    "\n",
    "\n",
    "dataset = torchvision.datasets.MNIST('data', train=True, download=True, transform=transforms.ToTensor())\n",
    "means, stds = compute_dataset_stats(dataset)\n",
    "\n",
    "print(\"\\MNIST stats on the train set:\")\n",
    "print(f\"Mean: {means[0]:.4f}\")\n",
    "print(f\"Std: {stds[0]:.4f}\")\n",
    "\n",
    "\n",
    "dataset = torchvision.datasets.MNIST('data', train=False, download=True, transform=transforms.ToTensor())\n",
    "means, stds = compute_dataset_stats(dataset)\n",
    "\n",
    "print(\"\\MNIST stats on the test set:\")\n",
    "print(f\"Mean: {means[0]:.4f}\")\n",
    "print(f\"Std: {stds[0]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The core idea here is that we train a network for given values so that whenever we feed in new input values, such as from the validation set, the batch will have similar first-order statistics. But is this hypothesis really important given the architecture of the network? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One advantage of our code is that we can now manipulate these two values, to see if starting from a different tuple of numbers, we obtain an accuracy value that is different.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first see what happens without normalization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T15:41:54.174272Z",
     "iopub.status.busy": "2024-12-22T15:41:54.174154Z",
     "iopub.status.idle": "2024-12-22T15:42:35.615633Z",
     "shell.execute_reply": "2024-12-22T15:42:35.615376Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy=0.9926\n"
     ]
    }
   ],
   "source": [
    "accuracy = main(mean=None, std=None)\n",
    "print(f'{accuracy=:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty much the same... but slightly better.\n",
    "\n",
    "What if we use standard numbers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T15:42:35.616749Z",
     "iopub.status.busy": "2024-12-22T15:42:35.616649Z",
     "iopub.status.idle": "2024-12-22T15:43:22.661051Z",
     "shell.execute_reply": "2024-12-22T15:43:22.660745Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "accuracy = main(mean=0., std=1.)\n",
    "print(f'{accuracy=:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result seems similar, but it's not enough to demonstrate that the mean and standard deviation have no effect on learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### computing accuracy on a regular grid of values\n",
    "\n",
    "I'm now going to push the boat out further, using a library that allows me to test several values and thus optimize the parameters. If the mean and deviation are so important, we'll converge on a fixed set of values, whereas if they're less important, the values can be quite scattered. In particular, this will allow us to choose an arbitrary value, such as a mean of 0 and a standard deviation of 1, better known as *normal* normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T15:43:22.662409Z",
     "iopub.status.busy": "2024-12-22T15:43:22.662303Z",
     "iopub.status.idle": "2024-12-22T15:43:22.664081Z",
     "shell.execute_reply": "2024-12-22T15:43:22.663793Z"
    }
   },
   "outputs": [],
   "source": [
    "model = 'LeNet'\n",
    "epochs = 30 # a bit more than the original example which had 15 epochs\n",
    "N_scan = 15\n",
    "\n",
    "means = np.linspace(-2, 3., N_scan, endpoint=True)\n",
    "stds = np.geomspace(0.02, 2., N_scan, endpoint=True)\n",
    "\n",
    "path_save_numpy =  f'numpy-{model}.npy'\n",
    "# %rm {path_save_numpy}\n",
    "if not(os.path.isfile(path_save_numpy)):\n",
    "    accuracy = np.empty((N_scan, N_scan))\n",
    "    for i_mean, mean in enumerate(means):\n",
    "        for i_std, std in enumerate(stds):\n",
    "            accuracy[i_mean, i_std] = main(mean=mean, std=std, epochs=epochs)\n",
    "    np.save(path_save_numpy, accuracy)\n",
    "else:\n",
    "    print(f'Loading {path_save_numpy}')\n",
    "    accuracy = np.load(path_save_numpy)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T15:43:22.669179Z",
     "iopub.status.busy": "2024-12-22T15:43:22.669072Z",
     "iopub.status.idle": "2024-12-22T15:43:22.800356Z",
     "shell.execute_reply": "2024-12-22T15:43:22.800160Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=figsize)\n",
    "CS = ax.contourf(means, stds, accuracy, n=20, cmap='viridis')\n",
    "CS2 = ax.contour(CS, levels=CS.levels, colors='k')\n",
    "fig.colorbar(CS, ax=ax, extendfrac=0)\n",
    "ax.set_title('Results for the LeNet model on the MNIST dataset')\n",
    "ax.set_xlabel('mean')\n",
    "ax.set_ylabel('std')\n",
    "fig;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One is most certainly interested by the best value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T15:43:22.801574Z",
     "iopub.status.busy": "2024-12-22T15:43:22.801455Z",
     "iopub.status.idle": "2024-12-22T15:43:22.803417Z",
     "shell.execute_reply": "2024-12-22T15:43:22.803177Z"
    }
   },
   "outputs": [],
   "source": [
    "mean_max, std_max = np.unravel_index(np.argmax(accuracy), accuracy.shape)\n",
    "print(f'Optimal value at indicies {mean_max, std_max}, with accuracy {accuracy[mean_max, std_max]:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T15:43:22.804722Z",
     "iopub.status.busy": "2024-12-22T15:43:22.804619Z",
     "iopub.status.idle": "2024-12-22T15:43:22.806229Z",
     "shell.execute_reply": "2024-12-22T15:43:22.806019Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f'Optimal value: of mean={means[mean_max]:.4f}, std={stds[std_max]:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or by the barycenter of the accuracy map:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T15:43:22.807479Z",
     "iopub.status.busy": "2024-12-22T15:43:22.807402Z",
     "iopub.status.idle": "2024-12-22T15:43:22.809138Z",
     "shell.execute_reply": "2024-12-22T15:43:22.808927Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f'Center of gravity: {np.sum(means*accuracy)/np.sum(accuracy):.4f}, {np.sum(stds*accuracy)/np.sum(accuracy):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a low variabilty of the accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T15:43:22.810383Z",
     "iopub.status.busy": "2024-12-22T15:43:22.810305Z",
     "iopub.status.idle": "2024-12-22T15:43:22.811881Z",
     "shell.execute_reply": "2024-12-22T15:43:22.811677Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f'Variabity of accuracy: {np.std(accuracy):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mostly driven by the worst value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T15:43:22.813147Z",
     "iopub.status.busy": "2024-12-22T15:43:22.813046Z",
     "iopub.status.idle": "2024-12-22T15:43:22.814668Z",
     "shell.execute_reply": "2024-12-22T15:43:22.814474Z"
    }
   },
   "outputs": [],
   "source": [
    "mean_min, std_min = np.unravel_index(np.argmin(accuracy), accuracy.shape)\n",
    "accuracy_min = accuracy[mean_min, std_min]\n",
    "print(f'Worst value at indicies {mean_min, std_min}, with accuracy {accuracy_min:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T15:43:22.815572Z",
     "iopub.status.busy": "2024-12-22T15:43:22.815496Z",
     "iopub.status.idle": "2024-12-22T15:43:22.817145Z",
     "shell.execute_reply": "2024-12-22T15:43:22.816864Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f'Worst value: of mean={means[mean_min]:.4f}, std={stds[std_min]:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variability on the plateau is very low:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T15:43:22.818126Z",
     "iopub.status.busy": "2024-12-22T15:43:22.818028Z",
     "iopub.status.idle": "2024-12-22T15:43:22.819941Z",
     "shell.execute_reply": "2024-12-22T15:43:22.819658Z"
    }
   },
   "outputs": [],
   "source": [
    "accuracy_best95 = accuracy[accuracy >np.percentile(accuracy, .05)].flatten()\n",
    "print(f'Mean of accuracy for the best 95%: {np.mean(accuracy_best95):.4f}')\n",
    "print(f'Variabity of accuracy for the best 95%: {np.std(accuracy_best95):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T15:43:22.820879Z",
     "iopub.status.busy": "2024-12-22T15:43:22.820778Z",
     "iopub.status.idle": "2024-12-22T15:43:22.970626Z",
     "shell.execute_reply": "2024-12-22T15:43:22.970313Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=figsize)\n",
    "ax.hist(accuracy_best95, bins=20, density=True)\n",
    "ax.set_title('Results for the LeNet model on the MNIST dataset')\n",
    "ax.set_xlabel('Accuracy')\n",
    "ax.set_xscale('logit')\n",
    "plt.xticks(rotation=30)\n",
    "ax.set_ylabel('Density')\n",
    "fig;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Such that we can confidently say that we do not need a 3 digits initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T15:43:22.971984Z",
     "iopub.status.busy": "2024-12-22T15:43:22.971858Z",
     "iopub.status.idle": "2024-12-22T15:44:09.907690Z",
     "shell.execute_reply": "2024-12-22T15:44:09.907403Z"
    }
   },
   "outputs": [],
   "source": [
    "accuracy = main(mean=0.5, std=0.5, verbose=False)\n",
    "print(f'{accuracy=:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### using optuna to search on a non-regular grid of values\n",
    "\n",
    "I'm now going to push the boat out further, using a library that allows me to test several values and thus optimize the parameters. If the mean and deviation are so important, we'll converge on a fixed set of values, whereas if they're less important, the values can be quite scattered. In particular, this will allow us to choose an arbitrary value, such as a mean of 0 and a standard deviation of 1, better known as *normal* normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T15:44:09.909004Z",
     "iopub.status.busy": "2024-12-22T15:44:09.908896Z",
     "iopub.status.idle": "2024-12-22T15:44:09.958676Z",
     "shell.execute_reply": "2024-12-22T15:44:09.958292Z"
    }
   },
   "outputs": [],
   "source": [
    "import optuna\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T15:44:09.960039Z",
     "iopub.status.busy": "2024-12-22T15:44:09.959954Z",
     "iopub.status.idle": "2024-12-22T15:44:09.962201Z",
     "shell.execute_reply": "2024-12-22T15:44:09.961938Z"
    }
   },
   "outputs": [],
   "source": [
    "path_save_optuna =  f'optuna-{model}.sqlite3'\n",
    "print(f'-> file {path_save_optuna} exists: {os.path.isfile(path_save_optuna)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T15:44:09.963124Z",
     "iopub.status.busy": "2024-12-22T15:44:09.963045Z",
     "iopub.status.idle": "2024-12-22T15:44:09.964533Z",
     "shell.execute_reply": "2024-12-22T15:44:09.964287Z"
    }
   },
   "outputs": [],
   "source": [
    "n_trials = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T15:44:09.965392Z",
     "iopub.status.busy": "2024-12-22T15:44:09.965316Z",
     "iopub.status.idle": "2024-12-22T15:44:09.966607Z",
     "shell.execute_reply": "2024-12-22T15:44:09.966435Z"
    }
   },
   "outputs": [],
   "source": [
    "# %rm {path_save_optuna}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T15:44:09.967417Z",
     "iopub.status.busy": "2024-12-22T15:44:09.967348Z",
     "iopub.status.idle": "2024-12-22T15:44:10.234712Z",
     "shell.execute_reply": "2024-12-22T15:44:10.234366Z"
    }
   },
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    mean = trial.suggest_float('mean', -1, 2., log=False)\n",
    "    std = trial.suggest_float('std', 0.05, 1., log=True)\n",
    "    accuracy = main(mean=mean, std=std, epochs=epochs)\n",
    "    return accuracy\n",
    "\n",
    "study = optuna.create_study(direction='maximize', load_if_exists=True, \n",
    "                            storage=f\"sqlite:///{path_save_optuna}\", study_name=model)\n",
    "if len(study.get_trials())<n_trials:\n",
    "    study.optimize(objective, n_trials=n_trials-len(study.get_trials()), show_progress_bar=True)\n",
    "print(50*'-.')\n",
    "print(\"Best params: \", study.best_params)\n",
    "print(\"Best value: \", study.best_value)\n",
    "print(50*'=')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T15:44:10.236102Z",
     "iopub.status.busy": "2024-12-22T15:44:10.236017Z",
     "iopub.status.idle": "2024-12-22T15:44:10.506469Z",
     "shell.execute_reply": "2024-12-22T15:44:10.506049Z"
    }
   },
   "outputs": [],
   "source": [
    "# https://optuna.readthedocs.io/en/stable/reference/visualization/matplotlib/generated/optuna.visualization.matplotlib.contour.html\n",
    "from optuna.visualization.matplotlib import plot_contour\n",
    "\n",
    "ax = plot_contour(study, params=[\"mean\", \"std\"], target_name=\"Accuracy\")\n",
    "fig = plt.gcf()\n",
    "ax.set_title('Results for the LeNet model on the MNIST dataset')\n",
    "fig.set_size_inches(figsize[0], figsize[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The picture is quite similar to the one above (note the log axis for `std`).\n",
    "\n",
    "An open question remains: why do these values matter when we have so many ways to counteract them, like setting bias values, scaling the weights, using batch normalization? \n",
    "\n",
    "And wait, how are the values of these parameters determined? How are the layer weights and biases initialized by default?\n",
    "\n",
    "For [nn.Linear](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html) and [nn.conv2D](https://pytorch.org/docs/stable/generated/torch.ao.nn.quantized.Conv2d.html), the weights are initialized from $\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})$, where $k = \\frac{1}{\\text{in\\_features}}$ for the linear layer and $k = \\frac{1}{C_\\text{in} * \\prod_{i=0}^{1}\\text{kernel\\_size}[i]}$.\n",
    "\n",
    "This is done by [Glorot initialization](https://pytorch.org/docs/stable/nn.init.html#torch.nn.init.kaiming_uniform_) :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T15:44:10.507924Z",
     "iopub.status.busy": "2024-12-22T15:44:10.507742Z",
     "iopub.status.idle": "2024-12-22T15:44:10.510464Z",
     "shell.execute_reply": "2024-12-22T15:44:10.510282Z"
    }
   },
   "outputs": [],
   "source": [
    "conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "print(f'The mean of weight and bias in the first convolutional layer is {conv1.weight.mean().item():.4f} and  {conv1.bias.mean().item():.4f}')\n",
    "print(f'The std of weight and bias in the first convolutional layer is {conv1.weight.std().item():.4f} and  {conv1.bias.std().item():.4f}')\n",
    "print(f' k= {1/3/3/1:.4f}, sqrt(k) = {np.sqrt(1/3/3/1):.4f}$')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### using optuna to search for another initialization point\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if for a given value for which we know the accuracy was worst (`mean=mean_min` and `std=std_min`), we can optimize the bias and weight intialization to get a better value, like that of the 95% best values obtained.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T15:44:10.511948Z",
     "iopub.status.busy": "2024-12-22T15:44:10.511835Z",
     "iopub.status.idle": "2024-12-22T15:44:10.553012Z",
     "shell.execute_reply": "2024-12-22T15:44:10.552688Z"
    }
   },
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    weight_init = trial.suggest_float('weight_init', 0.05, 20., log=True)\n",
    "    bias_init = trial.suggest_float('bias_init', 0.05, 20., log=True)\n",
    "    accuracy = main(mean=-1, std=0.1, weight_init=weight_init, bias_init=bias_init, epochs=epochs)\n",
    "    return accuracy\n",
    "\n",
    "study = optuna.create_study(direction='maximize', load_if_exists=True, \n",
    "                            storage=f\"sqlite:///{path_save_optuna}\", study_name=model + '-init_WB')\n",
    "if len(study.get_trials())<n_trials:\n",
    "    study.optimize(objective, n_trials=n_trials-len(study.get_trials()), show_progress_bar=True)\n",
    "print(50*'-.')\n",
    "print(\"Best params: \", study.best_params)\n",
    "print(\"Best value: \", study.best_value)\n",
    "print(50*'=')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it's a clear **yes** as we move that value above the range of 95% values computed on the range above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Mean of accuracy for the best 95%: {np.mean(accuracy_best95):.4f}')\n",
    "print(f'Variabity of accuracy for the best 95%: {np.std(accuracy_best95):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The ImageNet challenge and *residual networks* \n",
    "\n",
    "Second, let's tackle a real world problem: image classification with 1 million images and 1000 labels. For this we will use the well-known Resnet model defined in [Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385) as it givves a nice balance between simplicity and performance. In general, [Residual neural networks](https://en.wikipedia.org/wiki/Residual_neural_network) are widely used architectures for feed-forward networks appliead to image categorization. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://pytorch.org/hub/pytorch_vision_resnet/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T15:44:10.554560Z",
     "iopub.status.busy": "2024-12-22T15:44:10.554461Z",
     "iopub.status.idle": "2024-12-22T15:44:10.640912Z",
     "shell.execute_reply": "2024-12-22T15:44:10.640602Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.models import ResNet18_Weights\n",
    "\n",
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', weights=ResNet18_Weights.DEFAULT)\n",
    "# or any of these variants 'resnet34', 'resnet50', 'resnet101', 'resnet152',\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For image normalization in ResNet (and many other computer vision models), the standard values used are for ImageNet training:\n",
    "\n",
    "* Mean: `[0.485, 0.456, 0.406]` (for R,G,B channels respectively)\n",
    "* Std: `[0.229, 0.224, 0.225]`\n",
    "\n",
    "And which may be retrieved from te datasets' statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace with your ImageNet data path\n",
    "# Only transform to tensor and divide by 255\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor()  # Scales data to [0,1]\n",
    "])\n",
    "\n",
    "for type in ['train', 'test']:\n",
    "    dataset = torchvision.datasets.ImageFolder(f\"/Volumes/SSD1TO/Deep_learning/data/Imagenet_redux/{type}\", transform=transform)\n",
    "    means, stds = compute_dataset_stats(dataset)\n",
    "    print(f\"\\nImageNet stats on the {type} set:\")\n",
    "    print(f\"Means: {[round(m, 3) for m in means]}\")\n",
    "    print(f\"Stds: {[round(s, 3) for s in stds]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "These values have become standard practice even when training on other datasets, although technically you could calculate and use dataset-specific normalization values.\n",
    "\n",
    "These normalization values were first calculated in the early days of the rise of deep learning in computer vision, around 2012-2015. They come from calculating the mean and standard deviation per channel across the entire ImageNet training set of 1.2 million images, with the idea that each incoming batch should have the same first-order statistics. These values were widely adopted after the success of AlexNet (2012) and subsequent models such as VGG (2014) and ResNet (2015) on ImageNet.\n",
    "\n",
    "These values have since become a de facto standard in computer vision, with frameworks like PyTorch and TensorFlow using them as default values in their model zoos and tutorials. They're particularly associated with models trained on ImageNet, though they're also often used when training on other datasets due to their proven effectiveness in practice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training ResNet\n",
    "\n",
    "The cell below allows you to do everything: first load the libraries, then define the neural network, and finally define the learning and testing procedures to be applied to the database. The output accuracy value corresponds to the percentage of correctly classified images. For simplicity, we use pre-trained weights and the retraining protocol used in [Jean-Nicolas Jérémie, Laurent U Perrinet (2023). Ultra-Fast Image Categorization in Biology and in Neural Models](https://laurentperrinet.github.io/publication/jeremie-23-ultra-fast-cat/) and available in the following code [UltraFastCat.ipynb](https://nbviewer.org/github/JNJER/2022-03_UltraFastCat/blob/main/UltraFastCat.ipynb)\n",
    "\n",
    "In this cell, we'll isolate the two parameters used to set the mean and standard deviation applied to the normalization function we'll be manipulating throughout this book. Since we have color images, that is, 3 channels, this means that we are manipulating 6 variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T15:44:10.642105Z",
     "iopub.status.busy": "2024-12-22T15:44:10.641878Z",
     "iopub.status.idle": "2024-12-22T15:44:10.648170Z",
     "shell.execute_reply": "2024-12-22T15:44:10.647901Z"
    }
   },
   "outputs": [],
   "source": [
    "epochs = 1\n",
    "\n",
    "def train(model, device, train_loader, criterion, optimizer, epoch, log_interval=100, verbose=True):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if verbose and batch_idx % log_interval  == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "\n",
    "def test(model, device, test_loader, verbose=True):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    if verbose:\n",
    "        print('\\nTest set: Av Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "            correct, len(test_loader.dataset),\n",
    "            100. * correct / len(test_loader.dataset)))\n",
    "    return correct / len(test_loader.dataset)\n",
    "\n",
    "def main(mean_R, mean_G, mean_B, std_R, std_G, std_B, epochs=epochs, log_interval=100, verbose=False):\n",
    "    # Training settings\n",
    "    torch.manual_seed(1998) # FOOTIX rules !\n",
    "    train_kwargs = {'batch_size': 64}\n",
    "    test_kwargs = {'batch_size': 1000}\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "        cuda_kwargs = {'num_workers': 1,\n",
    "                    #    'pin_memory': True,\n",
    "                       'shuffle': True}\n",
    "        train_kwargs.update(cuda_kwargs)\n",
    "        test_kwargs.update(cuda_kwargs)\n",
    "    elif torch.backends.mps.is_available():\n",
    "        device = torch.device(\"mps\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((mean_R, mean_G, mean_B), (std_R, std_G, std_B))\n",
    "        ])\n",
    "    \n",
    "    DATADIR = '../Deep_learning/data/Imagenet_redux'\n",
    "    DATADIR = '/home/laurent/app54_nextcloud/2024_archives/2024_science/Deep_learning/data/Imagenet_full'\n",
    "    train_loader = torch.utils.data.DataLoader(datasets.ImageFolder(DATADIR + '/train', transform=transform), **train_kwargs)\n",
    "    test_loader = torch.utils.data.DataLoader(datasets.ImageFolder(DATADIR + '/val', transform=transform), **test_kwargs)\n",
    "\n",
    "    model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', weights=ResNet18_Weights.DEFAULT, verbose=False)\n",
    "    model = model.to(device)\n",
    "\n",
    "    # model.conv1.bias.data -= mean\n",
    "    # model.conv1.weight.data /= std\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    # optimizer = optim.Adadelta(model.parameters(), lr=1.0)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "    # scheduler = StepLR(optimizer, step_size=1, gamma=0.7)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, 'min')\n",
    "    for epoch in range(1, epochs):\n",
    "        train(model, device, train_loader, criterion, optimizer, epoch, log_interval=log_interval, verbose=verbose)\n",
    "        scheduler.step()\n",
    "\n",
    "    accuracy = test(model, device, test_loader, verbose=verbose)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Now that we've defined the entire protocol, we can test it in its most classic form, as delivered in the original code by 6 numbers with 3 digits precision:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T15:44:10.649374Z",
     "iopub.status.busy": "2024-12-22T15:44:10.649227Z",
     "iopub.status.idle": "2024-12-22T15:56:23.478178Z",
     "shell.execute_reply": "2024-12-22T15:56:23.477691Z"
    }
   },
   "outputs": [],
   "source": [
    "accuracy = main(0.485, 0.456, 0.406, 0.229, 0.224, 0.225)\n",
    "print(f'{accuracy=:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does it yield with normal parameters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T15:56:23.479644Z",
     "iopub.status.busy": "2024-12-22T15:56:23.479532Z",
     "iopub.status.idle": "2024-12-22T15:58:40.096099Z",
     "shell.execute_reply": "2024-12-22T15:58:40.095687Z"
    }
   },
   "outputs": [],
   "source": [
    "accuracy = main(0., 0., 0., 1., 1., 1.)\n",
    "print(f'{accuracy=:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### using optuna to search for another initialization point\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's scan the parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T15:58:40.097485Z",
     "iopub.status.busy": "2024-12-22T15:58:40.097363Z",
     "iopub.status.idle": "2024-12-22T15:58:40.099247Z",
     "shell.execute_reply": "2024-12-22T15:58:40.099008Z"
    }
   },
   "outputs": [],
   "source": [
    "model = 'ResNet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T15:58:40.100218Z",
     "iopub.status.busy": "2024-12-22T15:58:40.100094Z",
     "iopub.status.idle": "2024-12-23T00:31:00.052335Z",
     "shell.execute_reply": "2024-12-23T00:31:00.051865Z"
    }
   },
   "outputs": [],
   "source": [
    "N_scan = 15\n",
    "means = np.linspace(-3, 3, N_scan, endpoint=True)\n",
    "stds = np.geomspace(0.05, 1., N_scan, endpoint=True)\n",
    "\n",
    "path_save_numpy =  f'numpy-{model}.npy'\n",
    "if not(os.path.isfile(path_save_numpy)):\n",
    "    accuracy = np.empty((N_scan, N_scan))\n",
    "    for i_mean, mean in enumerate(means):\n",
    "        for i_std, std in enumerate(stds):\n",
    "            accuracy[i_mean, i_std] = main(mean, mean, mean, std, std, std, epochs=epochs)\n",
    "\n",
    "    np.save(path_save_numpy, accuracy)\n",
    "else:\n",
    "    accuracy = np.load(path_save_numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T00:31:00.054246Z",
     "iopub.status.busy": "2024-12-23T00:31:00.054041Z",
     "iopub.status.idle": "2024-12-23T00:31:00.257119Z",
     "shell.execute_reply": "2024-12-23T00:31:00.256801Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=figsize)\n",
    "pcm = ax.contourf(means, stds, accuracy, cmap='hot')\n",
    "fig.colorbar(pcm, ax=ax)\n",
    "ax.set_title('Results for the ResNet model on the ImageNet dataset')\n",
    "ax.set_xlabel('mean')\n",
    "ax.set_ylabel('std')\n",
    "fig;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's zoom around the central region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_scan = 15\n",
    "means = np.linspace(-.5, 1.5, N_scan, endpoint=True)\n",
    "stds = np.geomspace(0.20, 0.6, N_scan, endpoint=True)\n",
    "\n",
    "path_save_numpy =  f'numpy-{model}-zoom.npy'\n",
    "if not(os.path.isfile(path_save_numpy)):\n",
    "    accuracy = np.empty((N_scan, N_scan))\n",
    "    for i_mean, mean in enumerate(means):\n",
    "        for i_std, std in enumerate(stds):\n",
    "            accuracy[i_mean, i_std] = main(mean, mean, mean, std, std, std, epochs=epochs)\n",
    "\n",
    "    np.save(path_save_numpy, accuracy)\n",
    "else:\n",
    "    accuracy = np.load(path_save_numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=figsize)\n",
    "pcm = ax.contourf(means, stds, accuracy, cmap='hot')\n",
    "fig.colorbar(pcm, ax=ax)\n",
    "ax.set_title('Results for the ResNet model on the ImageNet dataset')\n",
    "ax.set_xlabel('mean')\n",
    "ax.set_ylabel('std')\n",
    "fig;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### using optuna to search for another initialization point\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now with optuna:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T00:31:00.258590Z",
     "iopub.status.busy": "2024-12-23T00:31:00.258469Z",
     "iopub.status.idle": "2024-12-23T00:31:00.260075Z",
     "shell.execute_reply": "2024-12-23T00:31:00.259844Z"
    }
   },
   "outputs": [],
   "source": [
    "path_save_optuna =  f'optuna-{model}.sqlite3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T00:31:00.261380Z",
     "iopub.status.busy": "2024-12-23T00:31:00.261275Z",
     "iopub.status.idle": "2024-12-23T00:31:00.262646Z",
     "shell.execute_reply": "2024-12-23T00:31:00.262407Z"
    }
   },
   "outputs": [],
   "source": [
    "# %rm {path_save_optuna}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T00:31:00.263780Z",
     "iopub.status.busy": "2024-12-23T00:31:00.263668Z",
     "iopub.status.idle": "2024-12-23T08:08:17.683717Z",
     "shell.execute_reply": "2024-12-23T08:08:17.683343Z"
    }
   },
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    mean = trial.suggest_float('mean', -.5, 1.5, log=False)\n",
    "    std = trial.suggest_float('std', 0.20, 0.6, log=True)\n",
    "    accuracy = main(mean, mean, mean, std, std, std, epochs=epochs)\n",
    "    return accuracy\n",
    "\n",
    "study = optuna.create_study(direction='maximize', load_if_exists=True, \n",
    "                            storage=f\"sqlite:///{path_save_optuna}\", study_name=model)\n",
    "if len(study.get_trials())<n_trials:\n",
    "    study.optimize(objective, n_trials=n_trials-len(study.get_trials()), show_progress_bar=True)\n",
    "print(50*'-.')\n",
    "print(\"Best params: \", study.best_params)\n",
    "print(\"Best value: \", study.best_value)\n",
    "print(50*'=')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T08:08:17.685059Z",
     "iopub.status.busy": "2024-12-23T08:08:17.684968Z",
     "iopub.status.idle": "2024-12-23T08:08:17.700887Z",
     "shell.execute_reply": "2024-12-23T08:08:17.700696Z"
    }
   },
   "outputs": [],
   "source": [
    "path_save_optuna, len(study.get_trials())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T08:08:17.702135Z",
     "iopub.status.busy": "2024-12-23T08:08:17.702030Z",
     "iopub.status.idle": "2024-12-23T08:08:17.707531Z",
     "shell.execute_reply": "2024-12-23T08:08:17.707332Z"
    }
   },
   "outputs": [],
   "source": [
    "study.optimize(objective, n_trials=n_trials-len(study.get_trials()), show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T08:08:17.708520Z",
     "iopub.status.busy": "2024-12-23T08:08:17.708401Z",
     "iopub.status.idle": "2024-12-23T08:08:17.918375Z",
     "shell.execute_reply": "2024-12-23T08:08:17.918028Z"
    }
   },
   "outputs": [],
   "source": [
    "# https://optuna.readthedocs.io/en/stable/reference/visualization/matplotlib/generated/optuna.visualization.matplotlib.contour.html\n",
    "from optuna.visualization.matplotlib import plot_contour\n",
    "\n",
    "ax = plot_contour(study, params=[\"mean\", \"std\"], target_name=\"Accuracy\")\n",
    "ax.set_title('Results for the ResNet model on the ImageNet dataset')\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(figsize[0], figsize[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appendix : looking for optimal values in RGB space\n",
    "\n",
    "We can further explore the 6-dimensional space:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T08:08:17.919547Z",
     "iopub.status.busy": "2024-12-23T08:08:17.919437Z",
     "iopub.status.idle": "2024-12-23T15:44:45.191553Z",
     "shell.execute_reply": "2024-12-23T15:44:45.190974Z"
    }
   },
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    mean_R = trial.suggest_float('mean_R', -1, 2., log=False)\n",
    "    mean_G = trial.suggest_float('mean_G', -1, 2., log=False)\n",
    "    mean_B = trial.suggest_float('mean_B', -1, 2., log=False)\n",
    "    std_R = trial.suggest_float('std_R', 0.05, 1., log=True)\n",
    "    std_G = trial.suggest_float('std_G', 0.05, 1., log=True)\n",
    "    std_B = trial.suggest_float('std_B', 0.05, 1., log=True)\n",
    "    accuracy = main(mean_R, mean_G, mean_B, std_R, std_G, std_B, epochs=epochs)\n",
    "    return accuracy\n",
    "\n",
    "study = optuna.create_study(direction='maximize', load_if_exists=True, \n",
    "                            storage=f\"sqlite:///{path_save_optuna}\", study_name=model + '-RGB')\n",
    "if len(study.get_trials())<n_trials:\n",
    "    study.optimize(objective, n_trials=n_trials-len(study.get_trials()), show_progress_bar=True)\n",
    "print(50*'-.')\n",
    "print(\"Best params: \", study.best_params)\n",
    "print(\"Best value: \", study.best_value)\n",
    "print(50*'=')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    mean_R = trial.suggest_float('mean_R', .40, .60, log=False)\n",
    "    mean_G = trial.suggest_float('mean_G', .40, .60, log=False)\n",
    "    mean_B = trial.suggest_float('mean_B', .40, .60, log=False)\n",
    "    std_R = trial.suggest_float('std_R', .15, .35, log=True)\n",
    "    std_G = trial.suggest_float('std_G', .15, .35, log=True)\n",
    "    std_B = trial.suggest_float('std_B', .15, .35, log=True)\n",
    "    accuracy = main(mean_R, mean_G, mean_B, std_R, std_G, std_B, epochs=epochs)\n",
    "    return accuracy\n",
    "\n",
    "study = optuna.create_study(direction='maximize', load_if_exists=True, \n",
    "                            storage=f\"sqlite:///{path_save_optuna}\", study_name=model + '-RGB_fine')\n",
    "if len(study.get_trials())<n_trials:\n",
    "    study.optimize(objective, n_trials=n_trials-len(study.get_trials()), show_progress_bar=True)\n",
    "print(50*'-.')\n",
    "print(\"Best params: \", study.best_params)\n",
    "print(\"Best value: \", study.best_value)\n",
    "print(50*'=')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axs = plt.subplots(3, 3, figsize=figsize)\n",
    "for i, c_mean in enumerate(['R', 'G', 'B']):\n",
    "    for j, c_std in enumerate(['R', 'G', 'B']):\n",
    "        ax = plot_contour(study, params=[\"mean_\" + c_mean, \"std_\" + c_std], target_name=\"Accuracy\")\n",
    "        # ax.set_title('Results for the ResNet model on the ImageNet dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.matplotlib.plot_parallel_coordinate(study, params=[\"mean_R\", \"mean_G\", \"mean_B\", \"std_R\", \"std_G\", \"std_B\"])\n",
    "plt.gcf().set_size_inches(figsize[0]*2, figsize[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## some book keeping for the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T15:44:45.192828Z",
     "iopub.status.busy": "2024-12-23T15:44:45.192726Z",
     "iopub.status.idle": "2024-12-23T15:44:45.212830Z",
     "shell.execute_reply": "2024-12-23T15:44:45.212497Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext watermark\n",
    "%watermark -i -h -m -v -p numpy,matplotlib,torch  -r -g -b"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "124f4064c4c9426db804891384185973": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "1310ff9e9e094e0cbf1e02eece69d951": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "16ba8d0a0b55423d812be542d1a5be34": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "1b8659c344eb4370bbe76b72b6a70c97": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "2f9cd48dcd104c5f9506508d77af2b38": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3f2a3ee8b4d34680a92f9ada1778b08d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_2f9cd48dcd104c5f9506508d77af2b38",
       "max": 200,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_1310ff9e9e094e0cbf1e02eece69d951",
       "tabbable": null,
       "tooltip": null,
       "value": 200
      }
     },
     "40bfd2dc4c404e67900f137aebfe744c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_fe3f4aaaa40a4d83ac8d981e574032f4",
        "IPY_MODEL_65172c7cbfcc49d0ad911580d71e2b7c",
        "IPY_MODEL_d7246f58d49c4ee2bc4c97669ec99c9e"
       ],
       "layout": "IPY_MODEL_883278e0ff694dbab89066462b25dddd",
       "tabbable": null,
       "tooltip": null
      }
     },
     "5069c001e5a44048a7db6dfb84860c33": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "65172c7cbfcc49d0ad911580d71e2b7c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_974bf932deef4670a987d94669792f6c",
       "max": 200,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_16ba8d0a0b55423d812be542d1a5be34",
       "tabbable": null,
       "tooltip": null,
       "value": 200
      }
     },
     "6bac8c8e86e24041a5f5befd7ea51dea": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "759a309084f144ba87814f3172edd2fc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "77ee107c46fa444a97888d42f1b96bd1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "7e05b47d41b14c6890d1951068552dc4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "845b235e3a0843b39fbb9be98ab374c8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_ef18bd8524ad438a97dfc5ae5f3531b5",
       "placeholder": "​",
       "style": "IPY_MODEL_77ee107c46fa444a97888d42f1b96bd1",
       "tabbable": null,
       "tooltip": null,
       "value": " 200/200 [7:37:15&lt;00:00, 137.07s/it]"
      }
     },
     "883278e0ff694dbab89066462b25dddd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "974bf932deef4670a987d94669792f6c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b2a7fe484294475d958d0b83613eabd4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_f1047974df424883a6fe705d074080d1",
        "IPY_MODEL_3f2a3ee8b4d34680a92f9ada1778b08d",
        "IPY_MODEL_845b235e3a0843b39fbb9be98ab374c8"
       ],
       "layout": "IPY_MODEL_759a309084f144ba87814f3172edd2fc",
       "tabbable": null,
       "tooltip": null
      }
     },
     "be18a8bd5789434a917bb6dc5436f09e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d7246f58d49c4ee2bc4c97669ec99c9e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_be18a8bd5789434a917bb6dc5436f09e",
       "placeholder": "​",
       "style": "IPY_MODEL_1b8659c344eb4370bbe76b72b6a70c97",
       "tabbable": null,
       "tooltip": null,
       "value": " 200/200 [7:36:27&lt;00:00, 136.13s/it]"
      }
     },
     "ef18bd8524ad438a97dfc5ae5f3531b5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f1047974df424883a6fe705d074080d1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_5069c001e5a44048a7db6dfb84860c33",
       "placeholder": "​",
       "style": "IPY_MODEL_7e05b47d41b14c6890d1951068552dc4",
       "tabbable": null,
       "tooltip": null,
       "value": "Best trial: 76. Best value: 0.69396: 100%"
      }
     },
     "fe3f4aaaa40a4d83ac8d981e574032f4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_6bac8c8e86e24041a5f5befd7ea51dea",
       "placeholder": "​",
       "style": "IPY_MODEL_124f4064c4c9426db804891384185973",
       "tabbable": null,
       "tooltip": null,
       "value": "Best trial: 181. Best value: 0.63608: 100%"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
