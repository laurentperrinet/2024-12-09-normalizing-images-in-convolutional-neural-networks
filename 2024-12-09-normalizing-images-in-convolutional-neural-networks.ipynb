{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's interesting to note that in deep learning, the evolution of architecture and techniques is very rapid, but that certain aspects can remain present for years in bits of code, without really knowing if they are totally necessary. Most of the time, we take for granted that these were optimized and this should not be taken care of.\n",
    "\n",
    "One such aspect is *input normalization*, which is used as input to most convolutional neural networks (CNNs) used to process visual images. This is all the more true as we often use in the community networks that are pre-trained for images normalized to given values, like VGG or ResNET. When you ask Github's copilot, it says that \n",
    "\n",
    ">    Image normalization in convolutional neural networks (CNNs) has several beneficial effects:\n",
    ">    1- Improved convergence: Normalization helps to stabilize and speed up the learning process by ensuring that pixel values are in a similar range, thus facilitating optimization.\n",
    ">    2- Reduced sensitivity to scale variations: Normalizing images reduces the model's sensitivity to scale variations in pixel values, which can improve model robustness.\n",
    ">    3- Prevention of neuron saturation: Unnormalized pixel values can lead to neuron saturation, which slows down learning. Normalization helps prevent this problem.\n",
    ">    4- Improved performance: In general, image normalization can lead to better model performance in terms of accuracy and generalization.\n",
    "\n",
    "\n",
    "**I'm interested here in whether these networks remain effective when we change the input normalization.** Indeed, as the weights of the first convolutional layer are learned, and as convolution kernels can be multiplied by arbitrary values thanks to the bias in the convolutions, normalizing to a certain value makes no sense, and simply normalizing does. This is even more evident when that values are given with 3 digits of precision! I propose here to show quantitatively that this is the case, first for a *historical* network [LeNet](https://en.wikipedia.org/wiki/LeNet) applied to the MNIST challenge, and then for [ResNet](https://en.wikipedia.org/wiki/Residual_neural_network) applied to ImageNet.\n",
    "\n",
    "\n",
    "<!-- TEASER_END -->\n",
    "\n",
    "Let's first initialize the notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(precision=6, suppress=True)\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "phi = (np.sqrt(5)+1)/2\n",
    "fig_width = 10\n",
    "figsize = (fig_width, fig_width/phi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -Uq -r requirements.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%mkdir -p data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The MNIST challenge and the *French Touche* \n",
    "\n",
    "First, let's explore the *LeNet* network  (Lecun, Y.; Bottou, L.; Bengio, Y.; Haffner, P. (1998). \"Gradient-based learning applied to document recognition\" (PDF). Proceedings of the IEEE. 86 (11): 2278â€“2324. doi:10.1109/5.726791. S2CID 14542261), whose objective is to categorize images of written digits, one of the first great successes of Multilayer neural networks. For this one, we're going to use the classic implementation, as proposed in the PyTorch library example series. \n",
    "\n",
    "The cell below allows you to do everything: first load the libraries, then define the neural network, and finally define the learning and testing procedures that are applied to the database. The output accuracy value corresponds to the percentage of letters that are correctly classified.\n",
    "\n",
    "In this cell, we'll isolate the two parameters used to set the mean and standard deviation applied to the normalization function, which we'll be manipulating in the course of this book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.0 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/Users/laurentperrinet/.venv/lib/python3.12/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/laurentperrinet/.venv/lib/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/laurentperrinet/.venv/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/laurentperrinet/.venv/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/usr/local/Cellar/python@3.12/3.12.7_1/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py\", line 641, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/usr/local/Cellar/python@3.12/3.12.7_1/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py\", line 1986, in _run_once\n",
      "    handle._run()\n",
      "  File \"/usr/local/Cellar/python@3.12/3.12.7_1/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Users/laurentperrinet/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/Users/laurentperrinet/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/Users/laurentperrinet/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/Users/laurentperrinet/.venv/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/Users/laurentperrinet/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/Users/laurentperrinet/.venv/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/Users/laurentperrinet/.venv/lib/python3.12/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/Users/laurentperrinet/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/Users/laurentperrinet/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/Users/laurentperrinet/.venv/lib/python3.12/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/Users/laurentperrinet/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/Users/laurentperrinet/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/Users/laurentperrinet/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/3p/m0g52j9j69z3gj8ktpgg1dm00000gn/T/ipykernel_69255/148962913.py\", line 2, in <module>\n",
      "    import torch\n",
      "  File \"/Users/laurentperrinet/.venv/lib/python3.12/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/laurentperrinet/.venv/lib/python3.12/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/laurentperrinet/.venv/lib/python3.12/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/laurentperrinet/.venv/lib/python3.12/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/laurentperrinet/.venv/lib/python3.12/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/laurentperrinet/.venv/lib/python3.12/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    }
   ],
   "source": [
    "# adapted from https://raw.githubusercontent.com/pytorch/examples/refs/heads/main/mnist/main.py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau\n",
    "\n",
    "epochs = 15\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output\n",
    "\n",
    "\n",
    "def train(model, device, train_loader, optimizer, epoch, log_interval=100, verbose=True):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if verbose and batch_idx % log_interval  == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "\n",
    "def test(model, device, test_loader, verbose=True):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    if verbose:\n",
    "        print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    return correct / len(test_loader.dataset)\n",
    "\n",
    "\n",
    "def main(mean, std, epochs=epochs, log_interval=100, verbose=False):\n",
    "    # Training settings\n",
    "    torch.manual_seed(1998) # FOOTIX rules !\n",
    "    train_kwargs = {'batch_size': 64}\n",
    "    test_kwargs = {'batch_size': 1000}\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "        cuda_kwargs = {'num_workers': 1,\n",
    "                       'pin_memory': True,\n",
    "                       'shuffle': True}\n",
    "        train_kwargs.update(cuda_kwargs)\n",
    "        test_kwargs.update(cuda_kwargs)\n",
    "    elif torch.backends.mps.is_available():\n",
    "        device = torch.device(\"mps\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "\n",
    "    if mean is None:\n",
    "        transform = transforms.ToTensor()\n",
    "    else:\n",
    "        transform=transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((mean,), (std,))\n",
    "            ])\n",
    "    dataset1 = datasets.MNIST('data', train=True, download=True,\n",
    "                       transform=transform)\n",
    "    train_loader = torch.utils.data.DataLoader(dataset1, **train_kwargs)\n",
    "\n",
    "    dataset2 = datasets.MNIST('data', train=False,\n",
    "                       transform=transform)\n",
    "    test_loader = torch.utils.data.DataLoader(dataset2, **test_kwargs)\n",
    "\n",
    "    model = Net().to(device)\n",
    "\n",
    "    if not mean is None:\n",
    "        model.conv1.bias.data -= mean\n",
    "        model.conv1.weight.data /= std\n",
    "\n",
    "    \n",
    "    optimizer = optim.Adadelta(model.parameters(), lr=1.0)\n",
    "    # scheduler = StepLR(optimizer, step_size=1, gamma=0.7)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, 'max')\n",
    "    for epoch in range(1, epochs+1):\n",
    "        train(model, device, train_loader, optimizer, epoch, log_interval=log_interval, verbose=verbose)\n",
    "        accuracy = test(model, device, test_loader, verbose=verbose)\n",
    "        scheduler.step(accuracy)\n",
    "    return accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can notice that I made one change by using the `ReduceLROnPlateau` scheduler instead of `StepLR`. In practice, this only changed the values I could test - run the notebook with enough epochs and the other scheduler to make your own opinion.\n",
    "\n",
    "Now that we've defined the entire protocol, we can test it in its most classic form, as delivered in the original code with 3 digits precision (!) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.314523\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.236322\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.448669\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.354365\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.205463\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.095123\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.071973\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.070792\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.065651\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.025615\n",
      "\n",
      "Test set: Average loss: 0.0515, Accuracy: 9843/10000 (98%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.027898\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.034083\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.121287\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.038534\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.092220\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.157338\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.026233\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.007240\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.002509\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.141234\n",
      "\n",
      "Test set: Average loss: 0.0401, Accuracy: 9874/10000 (99%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.002949\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.007469\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.231905\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.027577\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.012634\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.018396\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.012986\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.061146\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.018272\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.080821\n",
      "\n",
      "Test set: Average loss: 0.0368, Accuracy: 9877/10000 (99%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.068267\n",
      "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.004584\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.147518\n",
      "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.167045\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.086485\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.001989\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.137518\n",
      "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.128316\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.002762\n",
      "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.168111\n",
      "\n",
      "Test set: Average loss: 0.0308, Accuracy: 9903/10000 (99%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.017260\n",
      "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.073951\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.262954\n",
      "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.123041\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.065320\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.011981\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.073368\n",
      "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.027413\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.082088\n",
      "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.012099\n",
      "\n",
      "Test set: Average loss: 0.0346, Accuracy: 9901/10000 (99%)\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.001192\n",
      "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.003795\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.068516\n",
      "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.001422\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.083447\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.013740\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.008872\n",
      "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.002610\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.003221\n",
      "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.094118\n",
      "\n",
      "Test set: Average loss: 0.0347, Accuracy: 9908/10000 (99%)\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.060312\n",
      "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.131058\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.014429\n",
      "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.042458\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.002442\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.115311\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.109928\n",
      "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.046979\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.004923\n",
      "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.023398\n",
      "\n",
      "Test set: Average loss: 0.0346, Accuracy: 9893/10000 (99%)\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.074107\n",
      "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.015747\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.002602\n",
      "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.018806\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.133399\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.003179\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.022283\n",
      "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.074575\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.009551\n",
      "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.035168\n",
      "\n",
      "Test set: Average loss: 0.0417, Accuracy: 9907/10000 (99%)\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.000358\n",
      "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.052907\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.034857\n",
      "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.102631\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.001109\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.029547\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.009871\n",
      "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.154225\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.103956\n",
      "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.014548\n",
      "\n",
      "Test set: Average loss: 0.0368, Accuracy: 9890/10000 (99%)\n",
      "\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.035479\n",
      "Train Epoch: 10 [6400/60000 (11%)]\tLoss: 0.010002\n",
      "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.015567\n",
      "Train Epoch: 10 [19200/60000 (32%)]\tLoss: 0.003325\n",
      "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.020900\n",
      "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 0.012537\n",
      "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.048199\n",
      "Train Epoch: 10 [44800/60000 (75%)]\tLoss: 0.035610\n",
      "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.058221\n",
      "Train Epoch: 10 [57600/60000 (96%)]\tLoss: 0.044222\n",
      "\n",
      "Test set: Average loss: 0.0385, Accuracy: 9901/10000 (99%)\n",
      "\n",
      "Train Epoch: 11 [0/60000 (0%)]\tLoss: 0.019746\n",
      "Train Epoch: 11 [6400/60000 (11%)]\tLoss: 0.017226\n",
      "Train Epoch: 11 [12800/60000 (21%)]\tLoss: 0.137479\n",
      "Train Epoch: 11 [19200/60000 (32%)]\tLoss: 0.006017\n",
      "Train Epoch: 11 [25600/60000 (43%)]\tLoss: 0.023403\n",
      "Train Epoch: 11 [32000/60000 (53%)]\tLoss: 0.000249\n",
      "Train Epoch: 11 [38400/60000 (64%)]\tLoss: 0.072421\n",
      "Train Epoch: 11 [44800/60000 (75%)]\tLoss: 0.030280\n",
      "Train Epoch: 11 [51200/60000 (85%)]\tLoss: 0.026567\n",
      "Train Epoch: 11 [57600/60000 (96%)]\tLoss: 0.018811\n",
      "\n",
      "Test set: Average loss: 0.0475, Accuracy: 9904/10000 (99%)\n",
      "\n",
      "Train Epoch: 12 [0/60000 (0%)]\tLoss: 0.002535\n",
      "Train Epoch: 12 [6400/60000 (11%)]\tLoss: 0.210669\n",
      "Train Epoch: 12 [12800/60000 (21%)]\tLoss: 0.026025\n",
      "Train Epoch: 12 [19200/60000 (32%)]\tLoss: 0.003038\n",
      "Train Epoch: 12 [25600/60000 (43%)]\tLoss: 0.081428\n",
      "Train Epoch: 12 [32000/60000 (53%)]\tLoss: 0.000658\n",
      "Train Epoch: 12 [38400/60000 (64%)]\tLoss: 0.006770\n",
      "Train Epoch: 12 [44800/60000 (75%)]\tLoss: 0.042153\n",
      "Train Epoch: 12 [51200/60000 (85%)]\tLoss: 0.039968\n",
      "Train Epoch: 12 [57600/60000 (96%)]\tLoss: 0.003539\n",
      "\n",
      "Test set: Average loss: 0.0453, Accuracy: 9904/10000 (99%)\n",
      "\n",
      "Train Epoch: 13 [0/60000 (0%)]\tLoss: 0.058825\n",
      "Train Epoch: 13 [6400/60000 (11%)]\tLoss: 0.033515\n",
      "Train Epoch: 13 [12800/60000 (21%)]\tLoss: 0.002531\n",
      "Train Epoch: 13 [19200/60000 (32%)]\tLoss: 0.010319\n",
      "Train Epoch: 13 [25600/60000 (43%)]\tLoss: 0.021864\n",
      "Train Epoch: 13 [32000/60000 (53%)]\tLoss: 0.008203\n",
      "Train Epoch: 13 [38400/60000 (64%)]\tLoss: 0.001453\n",
      "Train Epoch: 13 [44800/60000 (75%)]\tLoss: 0.005181\n",
      "Train Epoch: 13 [51200/60000 (85%)]\tLoss: 0.001007\n",
      "Train Epoch: 13 [57600/60000 (96%)]\tLoss: 0.048749\n",
      "\n",
      "Test set: Average loss: 0.0394, Accuracy: 9900/10000 (99%)\n",
      "\n",
      "Train Epoch: 14 [0/60000 (0%)]\tLoss: 0.004093\n",
      "Train Epoch: 14 [6400/60000 (11%)]\tLoss: 0.000989\n",
      "Train Epoch: 14 [12800/60000 (21%)]\tLoss: 0.111468\n",
      "Train Epoch: 14 [19200/60000 (32%)]\tLoss: 0.001671\n",
      "Train Epoch: 14 [25600/60000 (43%)]\tLoss: 0.059040\n",
      "Train Epoch: 14 [32000/60000 (53%)]\tLoss: 0.115601\n",
      "Train Epoch: 14 [38400/60000 (64%)]\tLoss: 0.005570\n",
      "Train Epoch: 14 [44800/60000 (75%)]\tLoss: 0.006939\n",
      "Train Epoch: 14 [51200/60000 (85%)]\tLoss: 0.026367\n",
      "Train Epoch: 14 [57600/60000 (96%)]\tLoss: 0.005235\n",
      "\n",
      "Test set: Average loss: 0.0367, Accuracy: 9911/10000 (99%)\n",
      "\n",
      "Train Epoch: 15 [0/60000 (0%)]\tLoss: 0.028051\n",
      "Train Epoch: 15 [6400/60000 (11%)]\tLoss: 0.008038\n",
      "Train Epoch: 15 [12800/60000 (21%)]\tLoss: 0.008817\n",
      "Train Epoch: 15 [19200/60000 (32%)]\tLoss: 0.263984\n",
      "Train Epoch: 15 [25600/60000 (43%)]\tLoss: 0.002319\n",
      "Train Epoch: 15 [32000/60000 (53%)]\tLoss: 0.002771\n",
      "Train Epoch: 15 [38400/60000 (64%)]\tLoss: 0.039754\n",
      "Train Epoch: 15 [44800/60000 (75%)]\tLoss: 0.017313\n",
      "Train Epoch: 15 [51200/60000 (85%)]\tLoss: 0.058763\n",
      "Train Epoch: 15 [57600/60000 (96%)]\tLoss: 0.004250\n",
      "\n",
      "Test set: Average loss: 0.0383, Accuracy: 9923/10000 (99%)\n",
      "\n",
      "accuracy=0.9923\n"
     ]
    }
   ],
   "source": [
    "accuracy = main(mean=0.1307, std=0.3081, verbose=True)\n",
    "print(f'{accuracy=:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These exact same numbers were first introduced in that code on [Jan 17, 2017](https://github.com/pytorch/examples/commit/32c7386aef93737926069ee284d827f8e954e086) and these exact values have not changed since (up to the 3rd digit)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One advantage of our code is that we can now manipulate these two values, to see if starting from a different tuple of numbers, we obtain an accuracy value that is different.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first see what happens without normalization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy=0.9918\n"
     ]
    }
   ],
   "source": [
    "accuracy = main(mean=None, std=None)\n",
    "print(f'{accuracy=:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty much the same...\n",
    "\n",
    "What if we use standard numbers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy=0.9904\n"
     ]
    }
   ],
   "source": [
    "accuracy = main(mean=0., std=1.)\n",
    "print(f'{accuracy=:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result seems similar, but it's not enough to demonstrate that the mean and standard deviation have no effect on learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## computing accuracy on a regular grid of values\n",
    "\n",
    "I'm now going to push the boat out further, using a library that allows me to test several values and thus optimize the parameters. If the mean and deviation are so important, we'll converge on a fixed set of values, whereas if they're less important, the values can be quite scattered. In particular, this will allow us to choose an arbitrary value, such as a mean of 0 and a standard deviation of 1, better known as *normal* normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('numpy-LeNet.npy', True)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = 'LeNet'\n",
    "path_save_numpy =  f'numpy-{model}.npy'\n",
    "path_save_numpy, not(os.path.isfile(path_save_numpy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: numpy-LeNet.npy: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "%ls -l {path_save_numpy}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %rm {path_save_numpy}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 25 # a bit more than the original example which had 15 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'main' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i_mean, mean \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(means):\n\u001b[1;32m      9\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i_std, std \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(stds):\n\u001b[0;32m---> 10\u001b[0m             accuracy[i_mean, i_std] \u001b[38;5;241m=\u001b[39m \u001b[43mmain\u001b[49m(mean\u001b[38;5;241m=\u001b[39mmean, std\u001b[38;5;241m=\u001b[39mstd, epochs\u001b[38;5;241m=\u001b[39mepochs)\n\u001b[1;32m     12\u001b[0m     np\u001b[38;5;241m.\u001b[39msave(path_save_numpy, accuracy)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'main' is not defined"
     ]
    }
   ],
   "source": [
    "N_scan = 15\n",
    "means = np.linspace(-3, 3, N_scan, endpoint=True)\n",
    "stds = np.geomspace(0.1, 2., N_scan, endpoint=True)\n",
    "\n",
    "if not(os.path.isfile(path_save_numpy)):\n",
    "    accuracy = np.empty((N_scan, N_scan))\n",
    "    for i_mean, mean in enumerate(means):\n",
    "        for i_std, std in enumerate(stds):\n",
    "            accuracy[i_mean, i_std] = main(mean=mean, std=std, epochs=epochs)\n",
    "\n",
    "    np.save(path_save_numpy, accuracy)\n",
    "else:\n",
    "    accuracy = np.load(path_save_numpy)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'std')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x618.034 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=figsize)\n",
    "pcm = ax.contourf(means, stds, accuracy, cmap='hot')\n",
    "fig.colorbar(pcm, ax=ax)\n",
    "ax.set_title('Results for the LeNet model on the MNIST dataset')\n",
    "ax.set_xlabel('mean')\n",
    "ax.set_ylabel('std')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## using optuna to search on a non-regular grid of values\n",
    "\n",
    "I'm now going to push the boat out further, using a library that allows me to test several values and thus optimize the parameters. If the mean and deviation are so important, we'll converge on a fixed set of values, whereas if they're less important, the values can be quite scattered. In particular, this will allow us to choose an arbitrary value, such as a mean of 0 and a standard deviation of 1, better known as *normal* normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "model = 'LeNet'\n",
    "path_save_optuna =  f'optuna-{model}.sqlite3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %rm {path_save_optuna}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'study' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m     study\u001b[38;5;241m.\u001b[39moptimize(objective, n_trials\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m, show_progress_bar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;241m50\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest params: \u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mstudy\u001b[49m\u001b[38;5;241m.\u001b[39mbest_params)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest value: \u001b[39m\u001b[38;5;124m\"\u001b[39m, study\u001b[38;5;241m.\u001b[39mbest_value)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;241m50\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'study' is not defined"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    mean = trial.suggest_float('mean', -3, 3, log=False)\n",
    "    std = trial.suggest_float('std', 0.1, 2, log=True)\n",
    "    accuracy = main(mean=mean, std=std, epochs=epochs)\n",
    "    return accuracy\n",
    "\n",
    "if not(os.path.isfile(path_save_optuna)):\n",
    "    study = optuna.create_study(direction='maximize', load_if_exists=True, \n",
    "                                storage=f\"sqlite:///{path_save_optuna}\", study_name=model)\n",
    "    study.optimize(objective, n_trials=200, show_progress_bar=True)\n",
    "print(50*'-.')\n",
    "print(\"Best params: \", study.best_params)\n",
    "print(\"Best value: \", study.best_value)\n",
    "print(50*'=')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://optuna.readthedocs.io/en/stable/reference/visualization/matplotlib/generated/optuna.visualization.matplotlib.contour.html\n",
    "from optuna.visualization.matplotlib import plot_contour\n",
    "\n",
    "ax = plot_contour(study, params=[\"mean\", \"std\"], target_name=\"Accuracy\")\n",
    "fig = plt.gcf()\n",
    "ax.set_title('Results for the LeNet model on the MNIST dataset')\n",
    "fig.set_size_inches(figsize[0], figsize[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The ImageNet challenge and *residual networks* \n",
    "\n",
    "Second, let's tackle a real world problem: image classification with 1 million images and 1000 labels. For this we will use the well-known Resnet model defined in [Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385) as it givves a nice balance between simplicity and performance.\n",
    "\n",
    "The cell below allows you to do everything: first load the libraries, then define the neural network, and finally define the learning and testing procedures that are applied to the database. The output accuracy value corresponds to the percentage of images that are correctly classified. To simplify things, we will use pretrained weights and the retraining protocol which were used in [Jean-Nicolas JÃ©rÃ©mie, Laurent U Perrinet (2023). Ultra-Fast Image Categorization in biology and in neural models.](https://laurentperrinet.github.io/publication/jeremie-23-ultra-fast-cat/) and available in the following code [UltraFastCat.ipynb](https://nbviewer.org/github/JNJER/2022-03_UltraFastCat/blob/main/UltraFastCat.ipynb)\n",
    "\n",
    "In this cell, we'll isolate the two parameters used to set the mean and standard deviation applied to the normalization function, which we'll be manipulating in the course of this book. Since we have colored images, that is, 3 channels, it means we manipulate 6 variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://pytorch.org/hub/pytorch_vision_resnet/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.models import ResNet18_Weights\n",
    "\n",
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', weights=ResNet18_Weights.DEFAULT)\n",
    "# or any of these variants 'resnet34', 'resnet50', 'resnet101', 'resnet152',\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1\n",
    "\n",
    "def train(model, device, train_loader, criterion, optimizer, epoch, log_interval=100, verbose=True):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if verbose and batch_idx % log_interval  == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "\n",
    "def test(model, device, test_loader, verbose=True):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "\n",
    "    if verbose:\n",
    "        print('\\nTest set: Av Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "            correct, len(test_loader.dataset),\n",
    "            100. * correct / len(test_loader.dataset)))\n",
    "    return correct / len(test_loader.dataset)\n",
    "\n",
    "def main(mean_R, mean_G, mean_B, std_R, std_G, std_B, epochs=epochs, log_interval=100, verbose=False):\n",
    "    # Training settings\n",
    "    torch.manual_seed(1998) # FOOTIX rules !\n",
    "    train_kwargs = {'batch_size': 64}\n",
    "    test_kwargs = {'batch_size': 1000}\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "        cuda_kwargs = {'num_workers': 1,\n",
    "                       'pin_memory': True,\n",
    "                       'shuffle': True}\n",
    "        train_kwargs.update(cuda_kwargs)\n",
    "        test_kwargs.update(cuda_kwargs)\n",
    "    elif torch.backends.mps.is_available():\n",
    "        device = torch.device(\"mps\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((mean_R, mean_G, mean_B), (std_R, std_G, std_B))\n",
    "        ])\n",
    "    \n",
    "    DATADIR = '../Deep_learning/data/Imagenet_redux'\n",
    "    train_loader = torch.utils.data.DataLoader(datasets.ImageFolder(DATADIR + '/train', transform=transform), **train_kwargs)\n",
    "    test_loader = torch.utils.data.DataLoader(datasets.ImageFolder(DATADIR + '/val', transform=transform), **test_kwargs)\n",
    "\n",
    "    model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', weights=ResNet18_Weights.DEFAULT, verbose=False)\n",
    "    model = model.to(device)\n",
    "\n",
    "    # model.conv1.bias.data -= mean\n",
    "    model.conv1.weight.data /= std\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    # optimizer = optim.Adadelta(model.parameters(), lr=1.0)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "    # scheduler = StepLR(optimizer, step_size=1, gamma=0.7)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, 'min')\n",
    "    for epoch in range(1, epochs):\n",
    "        train(model, device, train_loader, criterion, optimizer, epoch, log_interval=log_interval, verbose=verbose)\n",
    "        scheduler.step()\n",
    "\n",
    "    accuracy = test(model, device, test_loader, verbose=verbose)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Now that we've defined the entire protocol, we can test it in its most classic form, as delivered in the original code by 6 numbers with 3 digits precision:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = main(0.485, 0.456, 0.406, 0.229, 0.224, 0.225)\n",
    "print(f'{accuracy=:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does it yield with normal parameters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = main(0., 0., 0., 1., 1., 1.)\n",
    "print(f'{accuracy=:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's scan the parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'ResNet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_scan = 15\n",
    "means = np.linspace(-3, 3, N_scan, endpoint=True)\n",
    "stds = np.geomspace(0.1, 2., N_scan, endpoint=True)\n",
    "\n",
    "path_save_numpy =  f'numpy-{model}.npy'\n",
    "if not(os.path.isfile(path_save_numpy)):\n",
    "    accuracy = np.empty((N_scan, N_scan))\n",
    "    for i_mean, mean in enumerate(means):\n",
    "        for i_std, std in enumerate(stds):\n",
    "            accuracy[i_mean, i_std] = main(mean, mean, mean, std, std, std, epochs=epochs)\n",
    "\n",
    "    np.save(path_save_numpy, accuracy)\n",
    "else:\n",
    "    accuracy = np.load(path_save_numpy)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=figsize)\n",
    "pcm = ax.contourf(means, stds, accuracy, cmap='hot')\n",
    "fig.colorbar(pcm, ax=ax)\n",
    "ax.set_title('Results for the ResNet model on the ImageNet dataset')\n",
    "ax.set_xlabel('mean')\n",
    "ax.set_ylabel('std')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now with optuna:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_save_optuna =  f'optuna-{model}.sqlite3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %rm {path_save_optuna}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    mean = trial.suggest_float('mean', -3, 3, log=False)\n",
    "    std = trial.suggest_float('std', 0.1, 2, log=True)\n",
    "    accuracy = main(mean, mean, mean, std, std, std, epochs=epochs)\n",
    "    return accuracy\n",
    "\n",
    "if not(os.path.isfile(path_save_optuna)):\n",
    "    study = optuna.create_study(direction='maximize', load_if_exists=True, \n",
    "                                storage=f\"sqlite:///{path_save_optuna}\", study_name=model)\n",
    "    study.optimize(objective, n_trials=200, show_progress_bar=True)\n",
    "print(50*'-.')\n",
    "print(\"Best params: \", study.best_params)\n",
    "print(\"Best value: \", study.best_value)\n",
    "print(50*'=')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://optuna.readthedocs.io/en/stable/reference/visualization/matplotlib/generated/optuna.visualization.matplotlib.contour.html\n",
    "from optuna.visualization.matplotlib import plot_contour\n",
    "\n",
    "ax = plot_contour(study, params=[\"mean\", \"std\"], target_name=\"Accuracy\")\n",
    "ax.set_title('Results for the ResNet model on the ImageNet dataset')\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(figsize[0], figsize[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    mean_R = trial.suggest_float('mean', -3, 3, log=False)\n",
    "    mean_G = trial.suggest_float('mean', -3, 3, log=False)\n",
    "    mean_B = trial.suggest_float('mean', -3, 3, log=False)\n",
    "    std_R = trial.suggest_float('std', 0.1, 2, log=True)\n",
    "    std_G = trial.suggest_float('std', 0.1, 2, log=True)\n",
    "    std_B = trial.suggest_float('std', 0.1, 2, log=True)\n",
    "    accuracy = main(mean_R, mean_G, mean_B, std_R, std_G, std_B, epochs=epochs)\n",
    "    return accuracy\n",
    "\n",
    "if not(os.path.isfile(path_save_optuna)):\n",
    "    study = optuna.create_study(direction='maximize', load_if_exists=True, \n",
    "                                storage=f\"sqlite:///{path_save_optuna}\", study_name=model)\n",
    "    study.optimize(objective, n_trials=200, show_progress_bar=True)\n",
    "print(50*'-.')\n",
    "print(\"Best params: \", study.best_params)\n",
    "print(\"Best value: \", study.best_value)\n",
    "print(50*'=')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## some book keeping for the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext watermark\n",
    "%watermark -i -h -m -v -p numpy,matplotlib,torch  -r -g -b"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
